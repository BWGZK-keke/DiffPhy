<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Think Before You Diffuse: LLMs-guided Physics-Aware Video Generation</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap" rel="stylesheet">
  <style>
    body {
      font-family: 'Inter', sans-serif;
      line-height: 1.6;
      max-width: 900px;
      margin: 40px auto;
      padding: 0 24px;
      background-color: #f4f6f8;
      color: #2c3e50;
    }

    h1 {
      text-align: center;
      font-size: 2.5rem;
      font-weight: 700;
      color: #1a1a1a;
      margin-bottom: 10px;
    }

    .authors,
    .affiliation {
      text-align: center;
      font-size: 1.1rem;
      color: #444;
    }

    .affiliation {
      font-size: 1rem;
      color: #666;
      margin-bottom: 30px;
    }

    .links {
      margin-top: 20px;
      text-align: center;
    }

    .links a {
      display: inline-block;
      margin: 10px 10px 0 0;
      padding: 10px 16px;
      font-size: 0.95rem;
      font-weight: 600;
      text-decoration: none;
      color: #ffffff;
      background-color: #007acc;
      border-radius: 8px;
      transition: background-color 0.3s ease;
    }

    .links a:hover {
      background-color: #005fa3;
    }

    .links a[disabled] {
      background-color: #999999;
      pointer-events: none;
    }

    .gif-row {
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 20px;
      margin: 40px 0;
      flex-wrap: wrap;
    }

    .gif-row img {
      width: 100%;
      max-width: 280px;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }

    h2 {
      font-size: 1.6rem;
      margin-top: 40px;
      color: #2c3e50;
    }

    p {
      font-size: 1.05rem;
      color: #333;
    }

    video {
      max-width: 100%;
      margin-top: 20px;
      border-radius: 12px;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }

    .footer {
      margin-top: 60px;
      font-size: 0.9em;
      color: #777;
      text-align: center;
    }
  </style>
</head>
<body>

  <h1>Think Before You Diffuse: LLMs-guided Physics-Aware Video Generation</h1>

  <div class="authors">
    Ke Zhang, Cihan Xiao, Jiacong Xu, Yiqun Mei, Vishal M. Patel
  </div>
  <div class="affiliation">
    Johns Hopkins University
  </div>

  <div class="links">
    <a href="https://arxiv.org/pdf/2505.21653" target="_blank">üìÑ Paper (arXiv)</a>
    <a href="#" onclick="alert('Code coming soon!')" style="background-color: #999999;">üíª Code (Coming Soon)</a>
    <a href="#" onclick="alert('Model coming soon!')" style="background-color: #999999;">üß† Model (Coming Soon)</a>
    <a href="#" onclick="alert('Dataset coming soon!')" style="background-color: #999999;">üìÅ Dataset (Coming Soon)</a>
  </div>

  <div class="gif-row">
    <img src="tutu.gif" alt="Demo GIF 1">
    <img src="sports.gif" alt="Demo GIF 2">
    <img src="sink.gif" alt="Demo GIF 3">
  </div>

  <h2>Demo Video</h2>
  <video controls>
    <source src="Demo-small.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>

  <h2>Description</h2>
  <p>
    Recent <span style="color:#1e90ff; font-weight:bold;">video diffusion models</span> have demonstrated their great capability in generating <span style="color:#16a085; font-weight:bold;">visually-pleasing results</span>, while synthesizing the correct <span style="color:#d35400; font-weight:bold;">physical effects</span> in generated videos remains challenging. The complexity of <span style="color:#9b59b6; font-weight:bold;">real-world motions</span>, <span style="color:#9b59b6; font-weight:bold;">interactions</span>, and <span style="color:#9b59b6; font-weight:bold;">dynamics</span> introduces great difficulties when learning physics from data.
  </p>

  <p>
    In this work, we propose <strong style="color:#e74c3c;">DiffPhy</strong>, a <span style="color:#2980b9;">generic framework</span> that enables <span style="color:#e67e22; font-weight:bold;">physically-correct</span> and <span style="color:#e67e22; font-weight:bold;">photo-realistic</span> video generation by fine-tuning a <span style="color:#2c3e50; font-weight:bold;">pre-trained video diffusion model</span>. Our method leverages <span style="color:#8e44ad; font-weight:bold;">large language models (LLMs)</span> to explicitly reason a <span style="color:#27ae60; font-weight:bold;">comprehensive physical context</span> from the text prompt and use it to guide the generation.
  </p>

  <p>
    To incorporate physical context into the diffusion model, we leverage a <span style="color:#8e44ad; font-weight:bold;">Multimodal Large Language Model (MLLM)</span> as a <span style="color:#c0392b;">supervisory signal</span> and introduce a set of <span style="color:#34495e; font-weight:bold;">novel training objectives</span> that jointly enforce <span style="color:#e67e22; font-weight:bold;">physical correctness</span> and <span style="color:#3498db; font-weight:bold;">semantic consistency</span> with the input text.
  </p>

  <p>
    We also establish a <span style="color:#f39c12; font-weight:bold;">high-quality physical video dataset</span> containing diverse <span style="color:#d35400;">physics-related actions and events</span> to facilitate effective fine-tuning. Extensive experiments on <span style="color:#2ecc71; font-weight:bold;">public benchmarks</span> demonstrate that <strong style="color:#e74c3c;">DiffPhy</strong> is able to produce <span style="color:#27ae60; font-weight:bold;">state-of-the-art results</span> across diverse <span style="color:#9b59b6;">physical scenarios</span>.
  </p>

  <div class="footer">
    ¬© 2025 Ke Zhang et al. ‚Äî Contact: kezhang [at] jhu.edu
  </div>

</body>
</html>
